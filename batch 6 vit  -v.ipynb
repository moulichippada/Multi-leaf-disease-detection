{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bP9Osv2kPn0e",
        "outputId": "38b5b960-4afd-426c-8d28-bc4ed67d3a0f"
      },
      "outputs": [],
      "source": [
        "\n",
        "# pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "PY8c8x00PccN",
        "outputId": "13c821e3-7ff2-483b-d0a1-0e900a3ebcd9"
      },
      "outputs": [],
      "source": [
        "# import cv2\n",
        "# import os\n",
        "# # img_size=200\n",
        "# data=[]\n",
        "# target=[]\n",
        "# categories=os.listdir(r'C:\\Users\\YOGI\\Downloads\\archive (1)\\New Plant Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\train')\n",
        "# # Location of Dataset\n",
        "# data_path = r'C:\\Users\\YOGI\\Downloads\\archive (Pla1New )\\nt Diseases Dataset(Augmented)\\New Plant Diseases Dataset(Augmented)\\train'\n",
        "# labels=[i for i in range(38)]\n",
        "# label_dict=dict(zip(categories,labels))\n",
        "# # print(label_dict)\n",
        "# # print(categories)\n",
        "# # print(labels)\n",
        "# d={}\n",
        "# for category in categories:\n",
        "#     folder_path=os.path.join(data_path,category)\n",
        "#     img_names=os.listdir(folder_path)\n",
        "#     img_paths=[folder_path+'\\\\'+i for i in img_names]\n",
        "#     d[category]=img_paths\n",
        "\n",
        "#             #if any exception rasied, the exception will be printed here. And pass to the neximage"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "IyezqtkGR2tM"
      },
      "outputs": [],
      "source": [
        "# total=530\n",
        "# for i in d: \n",
        "#     d[i]=d[i][:total]\n",
        "# print(len(d['Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for i in d:\n",
        "#     for img_name in d[i]:\n",
        "#         img=cv2.imread(img_name)\n",
        "#         try:\n",
        "#             # gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)           \n",
        "#             #Coverting the image into gray scale\n",
        "#             resized=cv2.resize(img,(224, 224))\n",
        "#             #resizing the gray scale into 100x100, since we need a fixed common size for all the images in the dataset\n",
        "#             data.append(resized)\n",
        "#             target.append(label_dict[i])\n",
        "#             #appending the image and the label(categorized) into the list (dataset)\n",
        "\n",
        "#         except Exception as e:\n",
        "#             print('Exception:',e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "_MQR3gq3PccN"
      },
      "outputs": [],
      "source": [
        "# import numpy as np\n",
        "# from keras.utils import to_categorical as to\n",
        "# data=np.array(data)\n",
        "# # data=np.reshape(data,(data.shape[0],224, 224, 3))\n",
        "# target=np.array(target)\n",
        "# new_target=to(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "HwCGi1ZmPccN"
      },
      "outputs": [],
      "source": [
        "# np.save('data',data)\n",
        "# np.save('target',new_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "zk5Mn7QBPccN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "# data=np.load(r'C:\\Users\\CSEGPUs-02\\Downloads\\yogi\\data.npy')\n",
        "# target=np.load(r'C:\\Users\\CSEGPUs-02\\Downloads\\yogi\\target.npy')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "yGvlNrtRPccO",
        "outputId": "c86b93ed-8e42-415f-d99e-dc45f5d3f71f"
      },
      "outputs": [],
      "source": [
        "# target.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "# target[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--WbnKfWPccO"
      },
      "source": [
        "# ViT B16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install --upgrade tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Iv8K57vPPccP"
      },
      "outputs": [],
      "source": [
        "# pip install distutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "UZ9Ju9I3PccP",
        "outputId": "9b1fa205-6984-40ee-c80e-56a0710b0074"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2.16.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "Ftdzcpk0PccQ",
        "outputId": "59f19951-3ca6-4140-ddc2-8b73b957e6ee"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras.layers as L\n",
        "# import tensorflow_addons as tfa\n",
        "import os,warnings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "BIpEVt0xPccQ"
      },
      "outputs": [],
      "source": [
        "image_size=224"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kagglehub in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.2.3)\n",
            "Requirement already satisfied: requests in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kagglehub) (2.31.0)\n",
            "Requirement already satisfied: tqdm in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from kagglehub) (4.66.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->kagglehub) (2024.2.2)\n",
            "Requirement already satisfied: colorama in c:\\users\\yogi\\appdata\\roaming\\python\\python312\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated `kagglehub` version, please consider updating (latest version: 0.2.7)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to model files: C:\\Users\\YOGI\\.cache\\kagglehub\\models\\spsayakpaul\\vision-transformer\\tensorFlow2\\vit-b16-classification\\1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "# Download latest version\n",
        "path = kagglehub.model_download(\"spsayakpaul/vision-transformer/tensorFlow2/vit-b16-classification\")\n",
        "print(\"Path to model files:\", path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-hub in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (0.16.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-hub) (1.26.4)\n",
            "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-hub) (4.25.3)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-hub) (2.16.0)\n",
            "Requirement already satisfied: tensorflow<2.17,>=2.16 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tf-keras>=2.14.1->tensorflow-hub) (2.16.1)\n",
            "Requirement already satisfied: tensorflow-intel==2.16.1 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2.1.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (3.3.0)\n",
            "Requirement already satisfied: packaging in c:\\users\\yogi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (24.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2.31.0)\n",
            "Requirement already satisfied: setuptools in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (69.5.1)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\yogi\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (1.62.1)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (3.2.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.43.0)\n",
            "Requirement already satisfied: rich in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (13.7.1)\n",
            "Requirement already satisfied: namex in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.0.8)\n",
            "Requirement already satisfied: optree in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2024.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (3.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\yogi\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (2.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\yogi\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow-intel==2.16.1->tensorflow<2.17,>=2.16->tf-keras>=2.14.1->tensorflow-hub) (0.1.2)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "[notice] A new release of pip is available: 24.0 -> 24.1.1\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow-hub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\YOGI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_hub\\resolver.py:498: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\YOGI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
            "\n",
            "WARNING:tensorflow:From c:\\Users\\YOGI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\YOGI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "# Load ViT-B16 model from TensorFlow Hub\n",
        "vit_model = hub.KerasLayer(path, trainable=True ,input_shape=(224,224,3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [],
      "source": [
        "# targett=target\n",
        "# targett.shape\n",
        "# # input_images_normalized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "vit_lambda = tf.keras.layers.Lambda(lambda x: vit_model(x))\n",
        "# predictions = vit_model(input_images_normalized)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "pehIyhD9PccQ"
      },
      "outputs": [],
      "source": [
        "# class Patches(L.Layer):\n",
        "#     def __init__(self, patch_size):\n",
        "#         super(Patches, self).__init__()\n",
        "#         self.patch_size = patch_size\n",
        "\n",
        "#     def call(self, images):\n",
        "#         batch_size = tf.shape(images)[0]\n",
        "#         patches = tf.image.extract_patches(\n",
        "#             images = images,\n",
        "#             sizes = [1, self.patch_size, self.patch_size, 1],\n",
        "#             strides = [1, self.patch_size, self.patch_size, 1],\n",
        "#             rates = [1, 1, 1, 1],\n",
        "#             padding = 'VALID',\n",
        "#         )\n",
        "#         patch_dims = patches.shape[-1]\n",
        "#         patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
        "#         return patches\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "OEYNewa9PccQ"
      },
      "outputs": [],
      "source": [
        "# from matplotlib import pyplot as plt \n",
        "# plt.figure(figsize=(4, 4))\n",
        "# batch_size = 16\n",
        "# patch_size = 7  # Size of the patches to be extract from the input images\n",
        "# num_patches = (image_size // patch_size) ** 2\n",
        "\n",
        "# for x in data[4:5]:\n",
        "#     image = x\n",
        "\n",
        "#     plt.imshow(image.astype('uint8'))\n",
        "#     plt.axis('off')\n",
        "\n",
        "#     resized_image = tf.image.resize(\n",
        "#     tf.convert_to_tensor([image]), size = (image_size, image_size)\n",
        "# )\n",
        "#     patches = Patches(patch_size)(resized_image)\n",
        "#     print(f'Image size: {image_size} X {image_size}')\n",
        "#     print(f'Patch size: {patch_size} X {patch_size}')\n",
        "#     print(f'Patches per image: {patches.shape[1]}')\n",
        "#     print(f'Elements per patch: {patches.shape[-1]}')\n",
        "\n",
        "#     n = int(np.sqrt(patches.shape[1]))\n",
        "#     plt.figure(figsize=(4, 4))\n",
        "\n",
        "# for i, patch in enumerate(patches[0]):\n",
        "#     ax = plt.subplot(n, n, i + 1)\n",
        "#     patch_img = tf.reshape(patch, (patch_size, patch_size, 3))\n",
        "#     plt.imshow(patch_img.numpy().astype('uint8'))\n",
        "#     plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [],
      "source": [
        "# data[0].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "-Z1MxOrBPccR",
        "outputId": "3d6e12ee-281d-4f69-b032-cc308f0c410b"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.Sequential([\n",
        "        vit_lambda,\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(1000, activation=\"relu\")\n",
        "        ],\n",
        "        name = 'vision_transformer')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pip install tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model.save('b6vit_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "# labels=[np.argmax(i) for i in target]\n",
        "# from collections import Counter \n",
        "# print(Counter(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [],
      "source": [
        "def extract_vit_features(model, dataset):\n",
        "    features=model.predict(dataset)\n",
        "    return np.vstack(features)\n",
        "# vit_features=extract_vit_features(model, data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "def create_resnet_model(input_shape):\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "    x = base_model.output\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    model = Model(inputs=base_model.input, outputs=x)\n",
        "    return model\n",
        "def extract_resnet_features(model, dataset):\n",
        "    features=model.predict(dataset)\n",
        "    return np.vstack(features)\n",
        "res_model=create_resnet_model((224,224,3))\n",
        "# res_features=extract_resnet_features(res_model, data)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "# res_model.save('b6resnet_model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(res_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print(vit_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from tensorflow.keras.models import Sequential\n",
        "# def build_sequential_model(input_shape, num_classes, res_features, vit_features):\n",
        "#     model = Sequential()\n",
        "#     model.add(layers.Flatten(input_shape=input_shape))\n",
        "#     model.add(layers.Dense(1024, activation='relu'))\n",
        "#     model.add(layers.Dense(256, activation='relu'))\n",
        "#     model.add(layers.Dense(64, activation='relu'))\n",
        "#     model.add(layers.Dense(num_classes, activation='softmax'))\n",
        "#     return model\n",
        "# # bottleneck_features = layers.Concatenate()([res_features, vit_features])\n",
        "# input_shape = (3048,) \n",
        "# num_classes = 15\n",
        "# # model2 = build_sequential_model(input_shape, num_classes, res_features, vit_features)\n",
        "# # model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "# # model2.summary()\n",
        "# # "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [],
      "source": [
        "# bottleneck_features=np.array(bottleneck_features)\n",
        "# bottleneck_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [],
      "source": [
        "# targett.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from sklearn.model_selection import train_test_split\n",
        "# train_data,test_data,train_target,test_target=train_test_split(bottleneck_features,targett,test_size=0.2)\n",
        "# train_data,val_data,train_target,val_target=train_test_split(train_data,train_target,test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model2.fit(train_data,train_target,epochs=10,validation_data=(val_data,val_target),batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "# los,acc=model2.evaluate(test_data,test_target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {},
      "outputs": [],
      "source": [
        "# print('accuracy:',acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [],
      "source": [
        "# model2.save('b6vit_resnet_model3.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pred=model2.predict(test_data)\n",
        "# pred=[np.argmax(i) for i in pred]\n",
        "# pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from keras.models import load_model\n",
        "# loaded_model2=load_model('b6vit_resnet_model2.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [],
      "source": [
        "l=[\n",
        " 'Apple___Black_rot',\n",
        " 'Apple___Cedar_apple_rust',\n",
        " 'Apple___healthy',\n",
        " 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot',\n",
        " 'Corn_(maize)___healthy',\n",
        " 'Corn_(maize)___Northern_Leaf_Blight',\n",
        " 'Grape___Black_rot',\n",
        " 'Grape___healthy',\n",
        " 'Grape__Leaf_blight(Isariopsis_Leaf_Spot)',\n",
        " 'Potato___Early_blight',\n",
        " 'Potato___healthy',\n",
        " 'Potato___Late_blight',\n",
        " 'Tomato___Bacterial_spot',\n",
        " 'Tomato___Early_blight',\n",
        " 'Tomato___healthy'\n",
        "]\n",
        "d={i:j for i,j in enumerate(l)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_items([(0, 'Apple___Black_rot'), (1, 'Apple___Cedar_apple_rust'), (2, 'Apple___healthy'), (3, 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot'), (4, 'Corn_(maize)___healthy'), (5, 'Corn_(maize)___Northern_Leaf_Blight'), (6, 'Grape___Black_rot'), (7, 'Grape___healthy'), (8, 'Grape__Leaf_blight(Isariopsis_Leaf_Spot)'), (9, 'Potato___Early_blight'), (10, 'Potato___healthy'), (11, 'Potato___Late_blight'), (12, 'Tomato___Bacterial_spot'), (13, 'Tomato___Early_blight'), (14, 'Tomato___healthy')])"
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "d.items()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "AG3d2bDTPccS",
        "outputId": "8683fce2-d6c9-4315-ff61-d21d9f032c07"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import confusion_matrix,classification_report\n",
        "# import seaborn as sns\n",
        "# predicted_classes = [np.argmax(i) for i in model2.predict(bottleneck_features)]\n",
        "# true_classes = [np.argmax(i) for i in targett]\n",
        "# class_labels = [i for i in range(15)]\n",
        "# true_classes=[d[i] for i in true_classes]\n",
        "# predicted_classes=[d[i] for i in predicted_classes]\n",
        "# cla_rep = classification_report(true_classes, predicted_classes)\n",
        "# confusionmatrix = confusion_matrix(true_classes, predicted_classes)\n",
        "# plt.figure(figsize = (5, 5))\n",
        "# print(cla_rep)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Counter(true_classes)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Counter(predicted_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "# for i in range(15):\n",
        "#     img=data[i*1000]\n",
        "#     img = Image.fromarray(img)\n",
        "#     img.save(\"image%s.png\"%str(i))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "Press CTRL+C to quit\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "127.0.0.1 - - [05/Jul/2024 13:09:03] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:09:03] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Jul/2024 13:09:03] \"GET /leaf.jpg HTTP/1.1\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:09:03] \"\u001b[33mGET /leaf.jpg HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "innnnnnnnnnnnnnnnn\n",
            "image shape:\n",
            "\n",
            " (1, 224, 224, 3)\n",
            "innnnnnnnnnnnnnnnn\n",
            "image shape:\n",
            "\n",
            " (1, 224, 224, 3)\n",
            "innnnnnnnnnnnnnnnn\n",
            "image shape:\n",
            "\n",
            " (1, 224, 224, 3)\n",
            "innnnnnnnnnnnnnnnn\n",
            "image shape:\n",
            "\n",
            " (1, 224, 224, 3)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
            "WARNING:tensorflow:From c:\\Users\\YOGI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:187: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From c:\\Users\\YOGI\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:187: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "ERROR:absl:hub.KerasLayer is trainable but has zero trainable weights.\n",
            "127.0.0.1 - - [05/Jul/2024 13:09:16] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:09:16] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Jul/2024 13:09:16] \"GET /leaf.jpg HTTP/1.1\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:09:16] \"\u001b[33mGET /leaf.jpg HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025B29426CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025B29426CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12s/stepWARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025B29426CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025B29426CA0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 12s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Jul/2024 13:09:27] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:09:27] \"POST /predict HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Jul/2024 13:09:27] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:09:27] \"POST /predict HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Jul/2024 13:09:27] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:09:27] \"POST /predict HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Jul/2024 13:09:27] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:09:27] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "innnnnnnnnnnnnnnnn\n",
            "image shape:\n",
            "\n",
            " (1, 224, 224, 3)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 267ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Jul/2024 13:09:30] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:09:30] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "innnnnnnnnnnnnnnnn\n",
            "image shape:\n",
            "\n",
            " (1, 224, 224, 3)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step\n",
            "innnnnnnnnnnnnnnnn\n",
            "image shape:\n",
            "\n",
            " (1, 224, 224, 3)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 287ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Jul/2024 13:09:31] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:09:31] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 272ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Jul/2024 13:09:32] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:09:32] \"POST /predict HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Jul/2024 13:19:50] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:19:50] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Jul/2024 13:19:50] \"GET /leaf.jpg HTTP/1.1\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:19:50] \"\u001b[33mGET /leaf.jpg HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "innnnnnnnnnnnnnnnn\n",
            "image shape:\n",
            "\n",
            " (1, 224, 224, 3)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 199ms/step\n",
            "innnnnnnnnnnnnnnnn\n",
            "image shape:\n",
            "\n",
            " (1, 224, 224, 3)\n",
            "innnnnnnnnnnnnnnnn\n",
            "image shape:\n",
            "\n",
            " (1, 224, 224, 3)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 832ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 608ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 181ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Jul/2024 13:19:59] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:19:59] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Jul/2024 13:19:59] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:19:59] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Jul/2024 13:19:59] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:19:59] \"POST /predict HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Jul/2024 13:26:03] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:26:03] \"GET / HTTP/1.1\" 200 -\n",
            "127.0.0.1 - - [05/Jul/2024 13:26:03] \"GET /leaf.jpg HTTP/1.1\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:26:03] \"\u001b[33mGET /leaf.jpg HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "innnnnnnnnnnnnnnnn\n",
            "image shape:\n",
            "\n",
            " (1, 224, 224, 3)\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 222ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "127.0.0.1 - - [05/Jul/2024 13:26:09] \"POST /predict HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [05/Jul/2024 13:26:09] \"POST /predict HTTP/1.1\" 200 -\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, render_template, request\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.resnet50 import preprocess_input, decode_predictions\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Model \n",
        "from keras.applications import Xception\n",
        "from keras.models import Model\n",
        "import pickle\n",
        "import keras\n",
        "app = Flask(__name__)\n",
        "from keras.models import load_model\n",
        "model2=load_model( r'b6vit_resnet_model3.keras')\n",
        "def preprocess_image(image, target_size):\n",
        "    if image.mode != \"RGB\":\n",
        "        image = image.convert(\"RGB\")\n",
        "    image = image.resize(target_size)\n",
        "    image = np.array(image)\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    return image\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if request.method == 'POST':\n",
        "        print(\"innnnnnnnnnnnnnnnn\")\n",
        "        file = request.files['file']\n",
        "        image = Image.open(file)\n",
        "        img = preprocess_image(image, target_size=(224, 224))\n",
        "        img=np.reshape(img,(1,224,224,3))\n",
        "        print('image shape:\\n\\n',img.shape) \n",
        "        res_feature=extract_resnet_features(res_model, img)\n",
        "        vit_feature=extract_vit_features(model, img)\n",
        "        bottleneck_features = layers.Concatenate()([res_feature, vit_feature])\n",
        "        preds=model2.predict(bottleneck_features)\n",
        "        labls=np.argmax(preds)\n",
        "        return d[labls]+'----'+str(labls)\n",
        "if __name__ == '__main__':\n",
        "    app.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
